{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNArzKoyfejUcjVN/4OCncv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrahmani/Marketing/blob/main/AIMarketing_Ch0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Kaggle Datasets in Google Colab**\n",
        "\n",
        "**1. Get Your Kaggle API Token:**\n",
        "\n",
        "Go to the Kaggle website (https://www.kaggle.com/) and log in to your account.\n",
        "Navigate to your account settings by clicking on your profile picture in the top right corner and selecting \"Account.\"\n",
        "Click on the “Settings” button.\n",
        "Scroll down to the \"API\" section. Click on the \"Create New API Token\" button.\n",
        "This will download a file named kaggle.json to your computer. This file contains your Kaggle API credentials.\n",
        "\n",
        "**2. Upload Your Kaggle API Token to Google Colab:**\n",
        "\n",
        "Open your Google Colab notebook. In the left sidebar, click on the \"Files\" icon.\n",
        "Click the \"Upload\" button.\n",
        "Select the kaggle.json file that you downloaded and upload it to the Colab environment."
      ],
      "metadata": {
        "id": "S0Rt_FijF7TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Install the Kaggle API Client in Colab:**\n",
        "\n",
        "In a code cell in your Colab notebook, run the following command to install the Kaggle API client:"
      ],
      "metadata": {
        "id": "aRDaf2rFGt-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "t3_m3di_C3oo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Configure the Kaggle API Credentials**:\n",
        "\n",
        "In a new code cell, run the following commands to create the .kaggle directory and move the kaggle.json file into it with the correct permissions:"
      ],
      "metadata": {
        "id": "NzjDDF_IG7HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/kaggle\n",
        "!mv kaggle.json ~/kaggle/   # or !mv /content/kaggle.json ~/kaggle/\n",
        "!chmod 600 ~/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tkn4HpLiitX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1588db13-03c3-4f89-ffea-72c0afc64b04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7MB4Gksv0zrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a6474c-98f2-4abc-b636-a22f3d8b8323"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 73 Apr 27 06:55 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Download the Dataset from Kaggle:**\n",
        "\n",
        "You need to know the name of the dataset as it appears on Kaggle. This usually follows the format username/dataset-name.\n",
        "Go to the Kaggle dataset page you want to use. The dataset name is typically found below the dataset title (e.g., vijayuv/onlineretail).\n",
        "In a new code cell in Colab, use the kaggle datasets download command followed by the dataset name and the -p flag to specify the directory where you want to download the files (e.g., ./data/)."
      ],
      "metadata": {
        "id": "xe_gR4izHTHF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4L1j9MSPYFSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbffbed-f364-43e4-b964-43e620117a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/vijayuv/onlineretail\n",
            "License(s): CC0-1.0\n",
            "Downloading onlineretail.zip to ./data\n",
            " 69% 5.00M/7.20M [00:00<00:00, 9.65MB/s]\n",
            "100% 7.20M/7.20M [00:00<00:00, 9.37MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d vijayuv/onlineretail -p ./data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al ./data/"
      ],
      "metadata": {
        "id": "nbNwukJ2ZD0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40b4822-5f41-43c5-b220-f486748ce611"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 51896\n",
            "drwxr-xr-x 2 root root     4096 Apr 27 07:06 .\n",
            "drwxr-xr-x 1 root root     4096 Apr 27 07:04 ..\n",
            "-rw-r--r-- 1 root root 45580638 Sep 21  2019 OnlineRetail.csv\n",
            "-rw-r--r-- 1 root root  7548702 Sep 21  2019 onlineretail.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Unzip the Dataset (if necessary):**\n",
        "\n",
        "Most Kaggle datasets are downloaded as zip files. You'll need to unzip them to access the individual data files (like CSV files)."
      ],
      "metadata": {
        "id": "16uft-yrHf5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Read the Data into Pandas:**\n",
        "\n",
        "Once the dataset is unzipped, you can use the pandas library to read the data files (e.g., CSV files) into a DataFrame:"
      ],
      "metadata": {
        "id": "QciB53CpHwHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./data/onlineretail.zip -d ./data/"
      ],
      "metadata": {
        "id": "kQHDLQrO15TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faef546b-e7e1-472e-8114-e6b8de0510f4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./data/onlineretail.zip\n",
            "  inflating: ./data/OnlineRetail.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Specify the encoding explicitly, for example 'latin1' or 'ISO-8859-1'\n",
        "df = pd.read_csv('./data/OnlineRetail.csv', encoding='latin1')\n",
        "# Now you can work with the DataFrame 'df'\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "DlnCj48b2Jur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d953f846-b28c-444b-cee1-8eaac030a3e3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
            "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
            "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
            "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
            "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('./data/OnlineRetail.csv', encoding='ISO-8859-1')\n",
        "\n",
        "print(\"Original DataFrame Shape:\", df.shape)\n",
        "\n",
        "# 1- Identify Missing Values\n",
        "print(\"\\n--- 1. Initial Missing Values ---\\n\")\n",
        "print(df.isnull().sum())\n",
        "initial_missing_count = df.isnull().sum().sum()\n",
        "print(f\"\\nTotal initial missing values: {initial_missing_count}\")\n",
        "\n",
        "# 2- Impute Missing Values with Mean\n",
        "print(\"\\n--- 2. Imputing Missing Values (UnitPrice) ---\\n\")\n",
        "print(\"Rows with missing UnitPrice before imputation:\")\n",
        "print(df[df['UnitPrice'].isnull()])\n",
        "\n",
        "mean_unit_price = df['UnitPrice'].mean()\n",
        "df['UnitPrice'].fillna(mean_unit_price, inplace=True)\n",
        "\n",
        "print(\"\\nRows with missing UnitPrice after imputation:\")\n",
        "print(df[df['UnitPrice'].isnull()])\n",
        "print(\"\\nMissing values after UnitPrice imputation:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 3- Remove rows or columns with a high percentage of missing values (> 50%)\n",
        "print(\"\\n--- 3. Removing Rows/Columns with High Missing Percentage (> 50%) ---\\n\")\n",
        "\n",
        "# Check column-wise missing percentage\n",
        "column_missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "columns_to_drop = column_missing_percentage[column_missing_percentage > 50].index\n",
        "print(\"Columns with > 50% missing values:\", columns_to_drop)\n",
        "\n",
        "if not columns_to_drop.empty:\n",
        "    print(\"\\nDataFrame info before dropping columns:\")\n",
        "    df.info()\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "    print(\"\\nDataFrame info after dropping columns:\")\n",
        "    df.info()\n",
        "else:\n",
        "    print(\"\\nNo columns found with more than 50% missing values.\")\n",
        "\n",
        "# Check row-wise missing percentage\n",
        "row_missing_percentage = (df.isnull().sum(axis=1) / df.shape[1]) * 100\n",
        "rows_to_drop = row_missing_percentage[row_missing_percentage > 50].index\n",
        "print(\"\\nNumber of rows with > 50% missing values:\", len(rows_to_drop))\n",
        "\n",
        "if not rows_to_drop.empty:\n",
        "    print(\"\\nFirst 5 rows with > 50% missing values before dropping:\")\n",
        "    print(df.loc[rows_to_drop.head()])\n",
        "    df.drop(index=rows_to_drop, inplace=True)\n",
        "    print(\"\\nDataFrame shape after dropping rows:\", df.shape)\n",
        "    print(\"\\nFirst 5 rows with > 50% missing values after dropping:\")\n",
        "    # Check if any still exist (should be none)\n",
        "    remaining_high_missing_rows = df[(df.isnull().sum(axis=1) / df.shape[1]) * 100 > 50]\n",
        "    if not remaining_high_missing_rows.empty:\n",
        "        print(remaining_high_missing_rows.head())\n",
        "    else:\n",
        "        print(\"No rows with > 50% missing values remain.\")\n",
        "else:\n",
        "    print(\"\\nNo rows found with more than 50% missing values.\")\n",
        "\n",
        "print(\"\\nMissing values after handling high percentage missing rows/columns:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "U97z4XTiJYXj",
        "outputId": "eebc49b7-cb35-46db-ecfd-449937d06701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame Shape: (541909, 8)\n",
            "\n",
            "--- 1. Initial Missing Values ---\n",
            "\n",
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n",
            "\n",
            "Total initial missing values: 136534\n",
            "\n",
            "--- 2. Imputing Missing Values (UnitPrice) ---\n",
            "\n",
            "Rows with missing UnitPrice before imputation:\n",
            "Empty DataFrame\n",
            "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country]\n",
            "Index: []\n",
            "\n",
            "Rows with missing UnitPrice after imputation:\n",
            "Empty DataFrame\n",
            "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country]\n",
            "Index: []\n",
            "\n",
            "Missing values after UnitPrice imputation:\n",
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n",
            "\n",
            "--- 3. Removing Rows/Columns with High Missing Percentage (> 50%) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-cb6bb5aebe9a>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitPrice'].fillna(mean_unit_price, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with > 50% missing values: Index([], dtype='object')\n",
            "\n",
            "No columns found with more than 50% missing values.\n",
            "\n",
            "Number of rows with > 50% missing values: 0\n",
            "\n",
            "No rows found with more than 50% missing values.\n",
            "\n",
            "Missing values after handling high percentage missing rows/columns:\n",
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}